{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T21:51:46.529129Z",
     "start_time": "2024-12-01T21:51:46.468988Z"
    }
   },
   "source": [
    "'''\n",
    "Name: Ananya Singh\n",
    "Class: CS677\n",
    "Date: 11/30/2024\n",
    "Homework Assignment #5\n",
    "Description of Problem: Given fetal cardiotocology data set, Naive Bayesian and Decision Tree Classification for identifying normal vs. non-normal fetus status based on fetal cardiograms\n",
    "'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Ananya Singh\\nClass: CS677\\nDate: 11/30/2024\\nHomework Assignment #5\\nDescription of Problem: Given fetal cardiotocology data set, Naive Bayesian and Decision Tree Classification for identifying normal vs. non-normal fetus status based on fetal cardiograms\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:10:40.424606Z",
     "start_time": "2024-12-02T03:10:40.218649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "CTG = 'CTG.xls'\n",
    "data = pd.read_excel(CTG, sheet_name=\"Raw Data\", engine=\"xlrd\") \n",
    "data = data.drop(index=0)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data[:2126]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(data.tail())"
   ],
   "id": "9a085dd94c4817f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          FileName       Date      SegFile       b       e    LBE     LB   AC  \\\n",
      "2121  S8001045.dsp 1998-06-06  CTG2124.txt  2059.0  2867.0  140.0  140.0  0.0   \n",
      "2122  S8001045.dsp 1998-06-06  CTG2125.txt  1576.0  2867.0  140.0  140.0  1.0   \n",
      "2123  S8001045.dsp 1998-06-06  CTG2126.txt  1576.0  2596.0  140.0  140.0  1.0   \n",
      "2124  S8001045.dsp 1998-06-06  CTG2127.txt  1576.0  3049.0  140.0  140.0  1.0   \n",
      "2125  S8001045.dsp 1998-06-06  CTG2128.txt  2796.0  3415.0  142.0  142.0  1.0   \n",
      "\n",
      "       FM   UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
      "2121  0.0  6.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0    5.0  2.0  \n",
      "2122  0.0  9.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0    5.0  2.0  \n",
      "2123  0.0  7.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0    5.0  2.0  \n",
      "2124  0.0  9.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0    5.0  2.0  \n",
      "2125  1.0  5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    1.0  1.0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:10:42.110867Z",
     "start_time": "2024-12-02T03:10:42.101474Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()",
   "id": "87fca03b9c86787d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 40 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   FileName  2126 non-null   object        \n",
      " 1   Date      2126 non-null   datetime64[ns]\n",
      " 2   SegFile   2126 non-null   object        \n",
      " 3   b         2126 non-null   float64       \n",
      " 4   e         2126 non-null   float64       \n",
      " 5   LBE       2126 non-null   float64       \n",
      " 6   LB        2126 non-null   float64       \n",
      " 7   AC        2126 non-null   float64       \n",
      " 8   FM        2126 non-null   float64       \n",
      " 9   UC        2126 non-null   float64       \n",
      " 10  ASTV      2126 non-null   float64       \n",
      " 11  MSTV      2126 non-null   float64       \n",
      " 12  ALTV      2126 non-null   float64       \n",
      " 13  MLTV      2126 non-null   float64       \n",
      " 14  DL        2126 non-null   float64       \n",
      " 15  DS        2126 non-null   float64       \n",
      " 16  DP        2126 non-null   float64       \n",
      " 17  DR        2126 non-null   float64       \n",
      " 18  Width     2126 non-null   float64       \n",
      " 19  Min       2126 non-null   float64       \n",
      " 20  Max       2126 non-null   float64       \n",
      " 21  Nmax      2126 non-null   float64       \n",
      " 22  Nzeros    2126 non-null   float64       \n",
      " 23  Mode      2126 non-null   float64       \n",
      " 24  Mean      2126 non-null   float64       \n",
      " 25  Median    2126 non-null   float64       \n",
      " 26  Variance  2126 non-null   float64       \n",
      " 27  Tendency  2126 non-null   float64       \n",
      " 28  A         2126 non-null   float64       \n",
      " 29  B         2126 non-null   float64       \n",
      " 30  C         2126 non-null   float64       \n",
      " 31  D         2126 non-null   float64       \n",
      " 32  E         2126 non-null   float64       \n",
      " 33  AD        2126 non-null   float64       \n",
      " 34  DE        2126 non-null   float64       \n",
      " 35  LD        2126 non-null   float64       \n",
      " 36  FS        2126 non-null   float64       \n",
      " 37  SUSP      2126 non-null   float64       \n",
      " 38  CLASS     2126 non-null   float64       \n",
      " 39  NSP       2126 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(37), object(2)\n",
      "memory usage: 664.5+ KB\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:10:44.320585Z",
     "start_time": "2024-12-02T03:10:44.297315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.loc[data['NSP'] == 2, 'NSP'] = 0\n",
    "data.loc[data['NSP'] == 3, 'NSP'] = 0\n",
    "\n",
    "print(data['NSP'].value_counts())\n",
    "print(data.head(40))"
   ],
   "id": "18d53cf40612d2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSP\n",
      "1.0    1655\n",
      "0.0     471\n",
      "Name: count, dtype: int64\n",
      "        FileName       Date      SegFile      b       e    LBE     LB   AC  \\\n",
      "0   Variab10.txt 1996-12-01  CTG0001.txt  240.0   357.0  120.0  120.0  0.0   \n",
      "1     Fmcs_1.txt 1996-05-03  CTG0002.txt    5.0   632.0  132.0  132.0  4.0   \n",
      "2     Fmcs_1.txt 1996-05-03  CTG0003.txt  177.0   779.0  133.0  133.0  2.0   \n",
      "3     Fmcs_1.txt 1996-05-03  CTG0004.txt  411.0  1192.0  134.0  134.0  2.0   \n",
      "4     Fmcs_1.txt 1996-05-03  CTG0005.txt  533.0  1147.0  132.0  132.0  4.0   \n",
      "5     Fmcs_2.txt 1996-05-03  CTG0006.txt    0.0   953.0  134.0  134.0  1.0   \n",
      "6     Fmcs_2.txt 1996-05-03  CTG0007.txt  240.0   953.0  134.0  134.0  1.0   \n",
      "7     Hasc_1.txt 1995-02-22  CTG0008.txt   62.0   679.0  122.0  122.0  0.0   \n",
      "8     Hasc_1.txt 1995-02-22  CTG0009.txt  120.0   779.0  122.0  122.0  0.0   \n",
      "9     Hasc_1.txt 1995-02-22  CTG0010.txt  181.0  1192.0  122.0  122.0  0.0   \n",
      "10     Hasc3.txt 1995-02-22  CTG0011.txt    0.0  1199.0  151.0  151.0  0.0   \n",
      "11     Hasc3.txt 1995-02-22  CTG0012.txt   57.0  1074.0  150.0  150.0  0.0   \n",
      "12  Mcslrc_1.txt 1995-01-08  CTG0013.txt   52.0   840.0  131.0  131.0  4.0   \n",
      "13  Mcslrc_1.txt 1995-01-08  CTG0014.txt  531.0  1192.0  131.0  131.0  6.0   \n",
      "14  Mcslrc_2.txt 1995-01-08  CTG0015.txt    0.0  1199.0  130.0  130.0  7.0   \n",
      "15  Mcslrc_2.txt 1995-01-08  CTG0016.txt    0.0   718.0  130.0  130.0  4.0   \n",
      "16  Mcslrc_2.txt 1995-01-08  CTG0017.txt  537.0  1194.0  130.0  130.0  4.0   \n",
      "17  Mcslrc_2.txt 1995-01-08  CTG0018.txt    1.0   657.0  131.0  131.0  1.0   \n",
      "18  Mcslrc_3.txt 1995-01-08  CTG0019.txt    8.0   711.0  130.0  130.0  2.0   \n",
      "19  Mcslrc_3.txt 1995-01-08  CTG0020.txt    7.0  1194.0  130.0  130.0  6.0   \n",
      "20  Mcslrc_4.txt 1995-01-08  CTG0021.txt  298.0  1192.0  129.0  129.0  0.0   \n",
      "21  Mcslrc_4.txt 1995-01-08  CTG0022.txt    3.0   643.0  128.0  128.0  3.0   \n",
      "22  Mcslrc_4.txt 1995-01-08  CTG0023.txt  538.0  1194.0  128.0  128.0  0.0   \n",
      "23   Mmmfm_1.txt 1996-05-03  CTG0024.txt  510.0   664.0  128.0  128.0  0.0   \n",
      "24   Mmmfm_1.txt 1996-05-03  CTG0025.txt    8.0   612.0  128.0  128.0  0.0   \n",
      "25   Mmmfm_2.txt 1996-05-03  CTG0026.txt    0.0  1199.0  124.0  124.0  0.0   \n",
      "26   Mmmfm_2.txt 1996-05-03  CTG0027.txt  280.0   477.0  124.0  124.0  0.0   \n",
      "27   Mmmfm_2.txt 1996-05-03  CTG0028.txt  477.0  1191.0  124.0  124.0  0.0   \n",
      "28  Ammmip_6.txt 1995-02-22  CTG0029.txt    0.0  1199.0  132.0  132.0  0.0   \n",
      "29  Ammmip_6.txt 1995-02-22  CTG0030.txt  355.0  1013.0  132.0  132.0  0.0   \n",
      "30  Ammmip_5.txt 1995-02-22  CTG0031.txt    0.0  1199.0  132.0  132.0  0.0   \n",
      "31  Ammmip_5.txt 1995-02-22  CTG0032.txt    5.0   711.0  132.0  132.0  0.0   \n",
      "32  Ammmip_5.txt 1995-02-22  CTG0033.txt  472.0  1194.0  132.0  132.0  0.0   \n",
      "33  Ammmip_4.txt 1995-02-22  CTG0034.txt    0.0  1199.0  120.0  120.0  9.0   \n",
      "34  Ammmip_4.txt 1995-02-22  CTG0035.txt  537.0  1196.0  120.0  120.0  6.0   \n",
      "35  Ammmip_4.txt 1995-02-22  CTG0036.txt   10.0   835.0  120.0  120.0  5.0   \n",
      "36  Ammmip_3.txt 1995-02-22  CTG0037.txt    0.0  1199.0  115.0  115.0  6.0   \n",
      "37  Ammmip_3.txt 1995-02-22  CTG0038.txt    1.0   659.0  114.0  114.0  3.0   \n",
      "38  Ammmip_3.txt 1995-02-22  CTG0039.txt  393.0  1194.0  115.0  115.0  5.0   \n",
      "39  Ammmip_2.txt 1995-02-22  CTG0040.txt   26.0  1014.0  115.0  115.0  9.0   \n",
      "\n",
      "       FM    UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
      "0     0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "1     0.0   4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "2     0.0   5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "3     0.0   6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "4     0.0   5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "5     0.0  10.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  0.0  \n",
      "6     0.0   9.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  0.0  \n",
      "7     0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "8     0.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "9     0.0   3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "10    0.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0   10.0  0.0  \n",
      "11    0.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0   10.0  0.0  \n",
      "12   57.0   6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "13  147.0   4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "14  489.0   5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "15  273.0   3.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "16  290.0   3.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "17  251.0   2.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  0.0  \n",
      "18  317.0   4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "19  557.0   6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "20  304.0   4.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  0.0  \n",
      "21  272.0   2.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "22  219.0   2.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  0.0  \n",
      "23    0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "24    0.0   2.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "25    0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "26    0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "27    0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  0.0  \n",
      "28  162.0   1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  0.0  \n",
      "29   65.0   0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  1.0  \n",
      "30  129.0   2.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  1.0  \n",
      "31   79.0   3.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  1.0  \n",
      "32   64.0   1.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0   0.0    7.0  1.0  \n",
      "33  123.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "34   56.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "35   90.0   6.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "36   95.0   6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "37    0.0   3.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
      "38   52.0   3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "39   54.0   5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
      "\n",
      "[40 rows x 40 columns]\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:18:13.306734Z",
     "start_time": "2024-12-02T03:18:13.269628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selected_features = ['MSTV', 'Width', 'Mode', 'Variance']\n",
    "X = data[selected_features]\n",
    "y = data['NSP']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler() # https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "X_train_scaled = scaler.fit_transform(X_train) # use fit the scaler on the training data and then apply to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# training on Xtrain\n",
    "nb_classifier = GaussianNB() # https://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "nb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict class labels in Xtest\n",
    "y_pred = nb_classifier.predict(X_test_scaled) # make predictions\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{accuracy*100:.2f}%\")"
   ],
   "id": "82f6e11a297d8a63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.16%\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:18:15.238303Z",
     "start_time": "2024-12-02T03:18:15.231586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "confusion_matrix_nb = confusion_matrix(y_test, y_pred) # https://scikit-learn.org/dev/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "print(confusion_matrix_nb)"
   ],
   "id": "1aedd1a607c18d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 39 195]\n",
      " [ 69 760]]\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T21:52:13.596459Z",
     "start_time": "2024-12-01T21:52:13.579813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42) #https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "dt_classifier.fit(X_train, y_train) # using same 50/50 split from earlier question\n",
    "\n",
    "# make predictions based on Xtest\n",
    "dt_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(f\"{dt_accuracy*100:.2f}%\")"
   ],
   "id": "b914663b204605b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.49%\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T21:52:33.965456Z",
     "start_time": "2024-12-01T21:52:33.957989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt_confusion_matrix = confusion_matrix(y_test, dt_pred)\n",
    "print(dt_confusion_matrix)"
   ],
   "id": "292c5cd8fbd98773",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  54]\n",
      " [ 79 750]]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:19:16.815298Z",
     "start_time": "2024-12-02T01:19:16.177332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = data[selected_features]\n",
    "y = data['NSP']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# take N = 1, . . . , 10 and d = 1, 2, . . . , 5\n",
    "NValues= range(1, 11)\n",
    "dValues = range(1, 6)\n",
    "error_rates = np.zeros((len(NValues), len(dValues))) # stores error rates for different combinations of N and d \n",
    "\n",
    "'''\n",
    "we need to test every possible combination of N and d (number of trees and max depth) params\n",
    "for each \"iteration\":\n",
    "    create a Random Forest model with the param\n",
    "    train it\n",
    "    make predictions on test data\n",
    "    calculate the error rate\n",
    "    store it in error_rates matrix for the combination\n",
    "'''\n",
    "for i, n_trees in enumerate(NValues):\n",
    "    for j, max_depth in enumerate(dValues):\n",
    "        rf = RandomForestClassifier( # https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "            n_estimators=n_trees,\n",
    "            max_depth=max_depth,\n",
    "            criterion='entropy', # use ”entropy” as splitting criteria\n",
    "            random_state=42\n",
    "        )\n",
    "        rf.fit(X_train, y_train) # train rf on training data\n",
    "        y_pred = rf.predict(X_test) # after training, model makes predictions on new data\n",
    "        error_rate = 1 - accuracy_score(y_test, y_pred) # calculate the error rate \n",
    "        error_rates[i, j] = error_rate # store it in error_rates matrix for the combination\n",
    "\n",
    "'''\n",
    "heatmap is effective way to visualize and compare results with two different params\n",
    "here we have 50 different combinations so now we can see all the results together\n",
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(error_rates) # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "plt.colorbar(label='Error Rate')\n",
    "plt.xlabel('d')\n",
    "plt.ylabel('N')\n",
    "plt.title('Error Rates')\n",
    "plt.xticks(range(len(dValues)), dValues)\n",
    "plt.yticks(range(len(NValues)), NValues)\n",
    "\n",
    "for i in range(len(NValues)):\n",
    "    for j in range(len(dValues)):\n",
    "        plt.text(j, i, f'{error_rates[i,j]:.2f}')\n",
    "\n",
    "plt.savefig('error_rates.pdf')\n",
    "plt.close()\n"
   ],
   "id": "4da788da7859cc43",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:39:28.657085Z",
     "start_time": "2024-12-02T01:39:28.648950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_error = 9999999999999999 # set min to maximum amount\n",
    "i_best_index = 0 \n",
    "j_best_index = 0\n",
    "\n",
    "for i in range(len(NValues)):\n",
    "    for j in range(len(dValues)):\n",
    "        if error_rates[i][j] < min_error:\n",
    "            min_error = error_rates[i][j]\n",
    "            i_best_index = i\n",
    "            j_best_index = j\n",
    "\n",
    "best_N = NValues[i_best_index]\n",
    "best_d = dValues[j_best_index]\n",
    "print(f\"N={best_N}, d={best_d}\")"
   ],
   "id": "bb7c0a6b5851e7a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=3, d=5\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:39:48.129002Z",
     "start_time": "2024-12-02T01:39:48.126801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_accuracy = 1 - error_rates[i_best_index, j_best_index]\n",
    "print(f\"Best accuracy: {best_accuracy*100:.2f}%\")"
   ],
   "id": "c5f346ff098e4f1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 89.84%\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T01:55:49.526023Z",
     "start_time": "2024-12-02T01:55:49.497609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_combo_rf = RandomForestClassifier(\n",
    "    n_estimators=best_N,\n",
    "    max_depth=best_d,\n",
    "    criterion='entropy',\n",
    "    random_state=42\n",
    ")\n",
    "best_combo_rf.fit(X_train, y_train)\n",
    "best_pred = best_combo_rf.predict(X_test)\n",
    "best_combo_confusion_matrix = confusion_matrix(y_test, best_pred)\n",
    "print(best_combo_confusion_matrix)"
   ],
   "id": "47e27057fe276428",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168  66]\n",
      " [ 42 787]]\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:25:27.014156Z",
     "start_time": "2024-12-02T02:25:26.847528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# naive bayesian\n",
    "true_positive = confusion_matrix_nb[1][1]\n",
    "false_positive = confusion_matrix_nb[0][1]\n",
    "true_negative = confusion_matrix_nb[0][0]\n",
    "false_negative = confusion_matrix_nb[1][0]\n",
    "\n",
    "if (true_positive + false_negative) > 0:\n",
    "    true_positive_rate = true_positive / (true_positive + false_negative)\n",
    "else:\n",
    "    true_positive_rate = 0\n",
    "if (true_negative + false_positive) > 0:\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "else:\n",
    "    true_negative_rate = 0\n",
    "    \n",
    "if (true_positive + false_positive + true_negative + false_negative) > 0:\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + false_positive + true_negative + false_negative)\n",
    "else:\n",
    "    accuracy = 0\n",
    "nb_results = [true_positive, false_positive, true_negative, false_negative, accuracy, true_positive_rate, true_negative_rate]\n",
    "\n",
    "# decision tree\n",
    "true_positive = dt_confusion_matrix[1][1]\n",
    "false_positive = dt_confusion_matrix[0][1]\n",
    "true_negative = dt_confusion_matrix[0][0]\n",
    "false_negative = dt_confusion_matrix[1][0]\n",
    "\n",
    "if (true_positive + false_negative) > 0:\n",
    "    true_positive_rate = true_positive / (true_positive + false_negative)\n",
    "else:\n",
    "    true_positive_rate = 0\n",
    "if (true_negative + false_positive) > 0:\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "else:\n",
    "    true_negative_rate = 0\n",
    "    \n",
    "if (true_positive + false_positive + true_negative + false_negative) > 0:\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + false_positive + true_negative + false_negative)\n",
    "else:\n",
    "    accuracy = 0\n",
    "dt_results = [true_positive, false_positive, true_negative, false_negative, accuracy, true_positive_rate, true_negative_rate]\n",
    "\n",
    "# random forest (best combo)\n",
    "true_positive = best_combo_confusion_matrix[1][1]\n",
    "false_positive = best_combo_confusion_matrix[0][1]\n",
    "true_negative = best_combo_confusion_matrix[0][0]\n",
    "false_negative = best_combo_confusion_matrix[1][0]\n",
    "\n",
    "if (true_positive + false_negative) > 0:\n",
    "    true_positive_rate = true_positive / (true_positive + false_negative)\n",
    "else:\n",
    "    true_positive_rate = 0\n",
    "if (true_negative + false_positive) > 0:\n",
    "    true_negative_rate = true_negative / (true_negative + false_positive)\n",
    "else:\n",
    "    true_negative_rate = 0\n",
    "    \n",
    "if (true_positive + false_positive + true_negative + false_negative) > 0:\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + false_positive + true_negative + false_negative)\n",
    "else:\n",
    "    accuracy = 0\n",
    "rf_results = [true_positive, false_positive, true_negative, false_negative, accuracy, true_positive_rate, true_negative_rate]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['naive bayesian', 'decision tree', 'random forest'],\n",
    "    'TP': [nb_results[0], dt_results[0], rf_results[0]],\n",
    "    'FP': [nb_results[1], dt_results[1], rf_results[1]],\n",
    "    'TN': [nb_results[2], dt_results[2], rf_results[2]],\n",
    "    'FN': [nb_results[3], dt_results[3], rf_results[3]],\n",
    "    'accuracy': [f\"{nb_results[4]*100:.2f}%\", f\"{dt_results[4]*100:.2f}%\", f\"{rf_results[4]*100:.2f}%\"],\n",
    "    'TPR': [nb_results[5], dt_results[5], rf_results[5]],\n",
    "    'TNR': [nb_results[6], dt_results[6], rf_results[6]]\n",
    "})\n",
    "\n",
    "results"
   ],
   "id": "861fe8bcd2e45ddf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Model   TP   FP   TN  FN accuracy       TPR       TNR\n",
       "0  naive bayesian  760  195   39  69   75.16%  0.916767  0.166667\n",
       "1   decision tree  750   54  180  79   87.49%  0.904704  0.769231\n",
       "2   random forest  787   66  168  42   89.84%  0.949337  0.717949"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive bayesian</td>\n",
       "      <td>760</td>\n",
       "      <td>195</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>75.16%</td>\n",
       "      <td>0.916767</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>750</td>\n",
       "      <td>54</td>\n",
       "      <td>180</td>\n",
       "      <td>79</td>\n",
       "      <td>87.49%</td>\n",
       "      <td>0.904704</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>787</td>\n",
       "      <td>66</td>\n",
       "      <td>168</td>\n",
       "      <td>42</td>\n",
       "      <td>89.84%</td>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74f1999da7527c3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
